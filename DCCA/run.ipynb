{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNPPaEC5hKCgKutlsdSzaP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmp4ZfPqj6ll","executionInfo":{"status":"ok","timestamp":1620588364924,"user_tz":-330,"elapsed":3702,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"d0429930-aab9-4822-d07c-d2e8b6ddea73"},"source":["!pip install q keras==2.0.2"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: q in /usr/local/lib/python3.7/dist-packages (2.6)\n","Requirement already satisfied: keras==2.0.2 in /usr/local/lib/python3.7/dist-packages (2.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.2) (3.13)\n","Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from keras==2.0.2) (0.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==2.0.2) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==2.0.2) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==2.0.2) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhCW_CZ2xx9H","executionInfo":{"status":"ok","timestamp":1620591493750,"user_tz":-330,"elapsed":1928,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"dc77f984-985b-4a8b-bb43-18fd1d1da9ee"},"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"theano\"\n","import keras.backend\n","keras.backend.set_image_dim_ordering('th')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using Theano backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"RNJ6WTn0kUV5","executionInfo":{"status":"ok","timestamp":1620591498879,"user_tz":-330,"elapsed":1316,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"1d285e0d-62ae-4890-ae3f-e64f275d7cfc"},"source":["import keras\n","keras.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.0.2'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vc3cwhVbkmIe","executionInfo":{"status":"ok","timestamp":1620588374131,"user_tz":-330,"elapsed":3866,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"7ad74873-790d-4f69-a627-9e810cc5cdcf"},"source":["!pip install q theano==0.9.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: q in /usr/local/lib/python3.7/dist-packages (2.6)\n","Requirement already satisfied: theano==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano==0.9.0) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano==0.9.0) (1.15.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano==0.9.0) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SB4MbZp8ltSR","executionInfo":{"status":"ok","timestamp":1620590010128,"user_tz":-330,"elapsed":1676,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"d8da8d11-3fcc-46e5-e356-539ee95e4ae6"},"source":["import theano\n","theano.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.9.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":872},"id":"oRB5cGldrw3F","executionInfo":{"status":"ok","timestamp":1620589963653,"user_tz":-330,"elapsed":60693,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"1c540752-90e3-4b64-cd4b-8c4121e65289"},"source":["!pip install q tensorflow==1.13.1"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: q in /usr/local/lib/python3.7/dist-packages (2.6)\n","Collecting tensorflow==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n","\u001b[K     |████████████████████████████████| 92.6MB 56kB/s \n","\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 39.7MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.3.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.32.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 48.7MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (56.1.0)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n","Installing collected packages: tensorboard, keras-applications, mock, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"NyWkPD2Fr2_7","executionInfo":{"status":"ok","timestamp":1620591508502,"user_tz":-330,"elapsed":1658,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"4899e98c-d74a-4766-b3bd-c941a4864fde"},"source":["import tensorflow\n","tensorflow.__version__"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.13.1'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"bJF6Q2GTl6gt","executionInfo":{"status":"ok","timestamp":1620591516038,"user_tz":-330,"elapsed":1124,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}}},"source":["from google.colab import drive"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PgAEHpLMmNHU","executionInfo":{"status":"ok","timestamp":1620591518317,"user_tz":-330,"elapsed":1075,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"5ba8ffe2-11b5-4c2d-fedd-6b2992392b6b"},"source":["drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LJ_C2bimmO6a","executionInfo":{"status":"ok","timestamp":1620591520753,"user_tz":-330,"elapsed":1039,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/BTPtrails/DeepCCA-Vahidoo\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"D07M4xhgmeOl","executionInfo":{"status":"ok","timestamp":1620591525081,"user_tz":-330,"elapsed":1089,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}}},"source":["try:\n","    import cPickle as thepickle\n","except ImportError:\n","    import _pickle as thepickle\n","\n","import gzip\n","import numpy as np\n","\n","from keras.callbacks import ModelCheckpoint\n","from utils import load_data, svm_classify\n","from linear_cca import linear_cca\n","from models import create_model\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqfu1JVamqQk","executionInfo":{"status":"ok","timestamp":1620591528555,"user_tz":-330,"elapsed":1050,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}}},"source":["def train_model(model, data1, data2, epoch_num, batch_size):\n","    \"\"\"\n","    trains the model\n","    # Arguments\n","        data1 and data2: the train, validation, and test data for view 1 and view 2 respectively. data should be packed\n","        like ((X for train, Y for train), (X for validation, Y for validation), (X for test, Y for test))\n","        epoch_num: number of epochs to train the model\n","        batch_size: the size of batches\n","    # Returns\n","        the trained model\n","    \"\"\"\n","\n","    # Unpacking the data\n","    train_set_x1, train_set_y1 = data1[0]\n","    valid_set_x1, valid_set_y1 = data1[1]\n","    test_set_x1, test_set_y1 = data1[2]\n","\n","    train_set_x2, train_set_y2 = data2[0]\n","    valid_set_x2, valid_set_y2 = data2[1]\n","    test_set_x2, test_set_y2 = data2[2]\n","\n","    # best weights are saved in \"temp_weights.hdf5\" during training\n","    # it is done to return the best model based on the validation loss\n","    checkpointer = ModelCheckpoint(filepath=\"temp_weights.h5\", verbose=1, save_best_only=True, save_weights_only=True)\n","\n","    # used dummy Y because labels are not used in the loss function\n","    model.fit([train_set_x1, train_set_x2], np.zeros(len(train_set_x1)),\n","              batch_size=batch_size, epochs=epoch_num, shuffle=True,\n","              validation_data=([valid_set_x1, valid_set_x2], np.zeros(len(valid_set_x1))),\n","              callbacks=[checkpointer])\n","\n","    model.load_weights(\"temp_weights.h5\")\n","\n","    results = model.evaluate([test_set_x1, test_set_x2], np.zeros(len(test_set_x1)), batch_size=batch_size, verbose=1)\n","\n","    print('loss on test data: ', results)\n","\n","    results = model.evaluate([valid_set_x1, valid_set_x2], np.zeros(len(valid_set_x1)), batch_size=batch_size, verbose=1)\n","    print('loss on validation data: ', results)\n","    return model\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"7I5CEuJ-mubU","executionInfo":{"status":"ok","timestamp":1620591532248,"user_tz":-330,"elapsed":1195,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}}},"source":["def test_model(model, data1, data2, outdim_size, apply_linear_cca):\n","    \"\"\"produce the new features by using the trained model\n","    # Arguments\n","        model: the trained model\n","        data1 and data2: the train, validation, and test data for view 1 and view 2 respectively.\n","            Data should be packed like\n","            ((X for train, Y for train), (X for validation, Y for validation), (X for test, Y for test))\n","        outdim_size: dimension of new features\n","        apply_linear_cca: if to apply linear CCA on the new features\n","    # Returns\n","        new features packed like\n","            ((new X for train - view 1, new X for train - view 2, Y for train),\n","            (new X for validation - view 1, new X for validation - view 2, Y for validation),\n","            (new X for test - view 1, new X for test - view 2, Y for test))\n","    \"\"\"\n","\n","    # producing the new features\n","    new_data = []\n","    for k in range(3):\n","        pred_out = model.predict([data1[k][0], data2[k][0]])\n","        r = int(pred_out.shape[1] / 2)\n","        new_data.append([pred_out[:, :r], pred_out[:, r:], data1[k][1]])\n","\n","    # based on the DCCA paper, a linear CCA should be applied on the output of the networks because\n","    # the loss function actually estimates the correlation when a linear CCA is applied to the output of the networks\n","    # however it does not improve the performance significantly\n","    if apply_linear_cca:\n","        w = [None, None]\n","        m = [None, None]\n","        print(\"Linear CCA started!\")\n","        w[0], w[1], m[0], m[1] = linear_cca(new_data[0][0], new_data[0][1], outdim_size)\n","        print(\"Linear CCA ended!\")\n","\n","        # Something done in the original MATLAB implementation of DCCA, do not know exactly why;)\n","        # it did not affect the performance significantly on the noisy MNIST dataset\n","        #s = np.sign(w[0][0,:])\n","        #s = s.reshape([1, -1]).repeat(w[0].shape[0], axis=0)\n","        #w[0] = w[0] * s\n","        #w[1] = w[1] * s\n","        ###\n","\n","        for k in range(3):\n","            data_num = len(new_data[k][0])\n","            for v in range(2):\n","                new_data[k][v] -= m[v].reshape([1, -1]).repeat(data_num, axis=0)\n","                new_data[k][v] = np.dot(new_data[k][v], w[v])\n","\n","    return new_data\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1dZlyK-m3jF","executionInfo":{"status":"ok","timestamp":1620591537980,"user_tz":-330,"elapsed":1045,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}}},"source":["############\n","# Parameters Section\n","\n","# the path to save the final learned features\n","save_to = './new_features.gz'\n","\n","# the size of the new space learned by the model (number of the new features)\n","outdim_size = 10\n","\n","# size of the input for view 1 and view 2\n","input_shape1 = 784\n","input_shape2 = 784\n","\n","# number of layers with nodes in each one\n","layer_sizes1 = [1024, 1024, 1024, outdim_size]\n","layer_sizes2 = [1024, 1024, 1024, outdim_size]\n","\n","# the parameters for training the network\n","learning_rate = 1e-3\n","epoch_num = 100\n","batch_size = 800\n","\n","# the regularization parameter of the network\n","# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n","reg_par = 1e-5\n","\n","# specifies if all the singular values should get used to calculate the correlation or just the top outdim_size ones\n","# if one option does not work for a network or dataset, try the other one\n","use_all_singular_values = False\n","\n","# if a linear CCA should get applied on the learned features extracted from the networks\n","# it does not affect the performance on noisy MNIST significantly\n","apply_linear_cca = True\n","\n","# end of parameters section\n","############\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttoeKk1bnZYw","executionInfo":{"status":"ok","timestamp":1620591551286,"user_tz":-330,"elapsed":8492,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"cafab32a-8dee-4eac-8c5d-19118a55dbe4"},"source":["    # Each view is stored in a gzip file separately. They will get downloaded the first time the code gets executed.\n","    # Datasets get stored under the datasets folder of user's Keras folder\n","    # normally under [Home Folder]/.keras/datasets/\n","    data1 = load_data('noisymnist_view1.gz', 'https://www2.cs.uic.edu/~vnoroozi/noisy-mnist/noisymnist_view1.gz')\n","    data2 = load_data('noisymnist_view2.gz', 'https://www2.cs.uic.edu/~vnoroozi/noisy-mnist/noisymnist_view2.gz')\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["loading data ...\n","loading data ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_GpGl0CncYH","executionInfo":{"status":"ok","timestamp":1620591561491,"user_tz":-330,"elapsed":8694,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"8dff2f36-8db8-4057-963c-5d893893ef2a"},"source":["# Building, training, and producing the new features by DCCA\n","model = create_model(layer_sizes1, layer_sizes2, input_shape1, input_shape2, learning_rate, reg_par, outdim_size, use_all_singular_values)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/BTPtrails/DeepCCA-Vahidoo/models.py:20: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n","  model.add(Merge([view1_model, view2_model], mode='concat'))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPoDUBzqnjJb","executionInfo":{"status":"ok","timestamp":1620591600650,"user_tz":-330,"elapsed":4009,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"dbf45a83-74ee-4400-88aa-057d04e8090a"},"source":["model.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","merge_1 (Merge)              (None, 20)                0         \n","=================================================================\n","Total params: 5,826,580.0\n","Trainable params: 5,826,580\n","Non-trainable params: 0.0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTjXz-WPoMIB","executionInfo":{"status":"ok","timestamp":1620596441414,"user_tz":-330,"elapsed":4821883,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"eac724fa-b4ed-41ed-d402-97952f6bb243"},"source":["model = train_model(model, data1, data2, epoch_num, batch_size)\n","new_data = test_model(model, data1, data2, outdim_size, apply_linear_cca)\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -3.4633Epoch 00000: val_loss improved from inf to -4.14677, saving model to temp_weights.h5\n","50000/50000 [==============================] - 46s - loss: -3.4698 - val_loss: -4.1468\n","Epoch 2/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -4.7011Epoch 00001: val_loss improved from -4.14677 to -5.11682, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -4.7048 - val_loss: -5.1168\n","Epoch 3/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -5.5337Epoch 00002: val_loss improved from -5.11682 to -5.76279, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -5.5351 - val_loss: -5.7628\n","Epoch 4/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -5.9924Epoch 00003: val_loss improved from -5.76279 to -5.92535, saving model to temp_weights.h5\n","50000/50000 [==============================] - 48s - loss: -5.9921 - val_loss: -5.9253\n","Epoch 5/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -6.2282Epoch 00004: val_loss improved from -5.92535 to -6.23272, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -6.2273 - val_loss: -6.2327\n","Epoch 6/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -6.4551Epoch 00005: val_loss improved from -6.23272 to -6.33617, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -6.4561 - val_loss: -6.3362\n","Epoch 7/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -6.6453Epoch 00006: val_loss improved from -6.33617 to -6.48090, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -6.6454 - val_loss: -6.4809\n","Epoch 8/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -6.7868Epoch 00007: val_loss improved from -6.48090 to -6.52792, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -6.7882 - val_loss: -6.5279\n","Epoch 9/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -6.9140Epoch 00008: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -6.9146 - val_loss: -6.4937\n","Epoch 10/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.0470Epoch 00009: val_loss improved from -6.52792 to -6.55080, saving model to temp_weights.h5\n","50000/50000 [==============================] - 48s - loss: -7.0476 - val_loss: -6.5508\n","Epoch 11/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.1532Epoch 00010: val_loss improved from -6.55080 to -6.84038, saving model to temp_weights.h5\n","50000/50000 [==============================] - 52s - loss: -7.1536 - val_loss: -6.8404\n","Epoch 12/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.2762Epoch 00011: val_loss improved from -6.84038 to -6.93900, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -7.2757 - val_loss: -6.9390\n","Epoch 13/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.3835Epoch 00012: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -7.3833 - val_loss: -6.8623\n","Epoch 14/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.4750Epoch 00013: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -7.4738 - val_loss: -6.8717\n","Epoch 15/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.5785Epoch 00014: val_loss improved from -6.93900 to -7.02244, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -7.5764 - val_loss: -7.0224\n","Epoch 16/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.6447Epoch 00015: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -7.6464 - val_loss: -6.9608\n","Epoch 17/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.7347Epoch 00016: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -7.7345 - val_loss: -6.8976\n","Epoch 18/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.8157Epoch 00017: val_loss improved from -7.02244 to -7.05236, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -7.8147 - val_loss: -7.0524\n","Epoch 19/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.8645Epoch 00018: val_loss improved from -7.05236 to -7.32781, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -7.8658 - val_loss: -7.3278\n","Epoch 20/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -7.9440Epoch 00019: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -7.9417 - val_loss: -7.1493\n","Epoch 21/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.0298Epoch 00020: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -8.0286 - val_loss: -7.2391\n","Epoch 22/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.0815Epoch 00021: val_loss improved from -7.32781 to -7.42398, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.0845 - val_loss: -7.4240\n","Epoch 23/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.1356Epoch 00022: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -8.1341 - val_loss: -7.3013\n","Epoch 24/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.2237Epoch 00023: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.2257 - val_loss: -7.3918\n","Epoch 25/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.2818Epoch 00024: val_loss improved from -7.42398 to -7.42613, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.2816 - val_loss: -7.4261\n","Epoch 26/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.3313Epoch 00025: val_loss improved from -7.42613 to -7.44537, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.3284 - val_loss: -7.4454\n","Epoch 27/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.3547Epoch 00026: val_loss improved from -7.44537 to -7.45511, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.3537 - val_loss: -7.4551\n","Epoch 28/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.4103Epoch 00027: val_loss improved from -7.45511 to -7.45538, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.4103 - val_loss: -7.4554\n","Epoch 29/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.4687Epoch 00028: val_loss improved from -7.45538 to -7.59934, saving model to temp_weights.h5\n","50000/50000 [==============================] - 50s - loss: -8.4678 - val_loss: -7.5993\n","Epoch 30/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.4874Epoch 00029: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.4845 - val_loss: -7.4119\n","Epoch 31/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.5405Epoch 00030: val_loss improved from -7.59934 to -7.63638, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.5380 - val_loss: -7.6364\n","Epoch 32/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.6355Epoch 00031: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.6333 - val_loss: -7.5769\n","Epoch 33/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.6060Epoch 00032: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.6004 - val_loss: -7.5014\n","Epoch 34/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.6070Epoch 00033: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.6029 - val_loss: -7.6070\n","Epoch 35/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.6539Epoch 00034: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.6493 - val_loss: -7.5770\n","Epoch 36/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.7117Epoch 00035: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.7074 - val_loss: -7.5851\n","Epoch 37/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.6665Epoch 00036: val_loss improved from -7.63638 to -7.65304, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.6681 - val_loss: -7.6530\n","Epoch 38/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.7119Epoch 00037: val_loss improved from -7.65304 to -7.66576, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.7144 - val_loss: -7.6658\n","Epoch 39/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.7785Epoch 00038: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.7791 - val_loss: -7.5330\n","Epoch 40/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.7668Epoch 00039: val_loss improved from -7.66576 to -7.79205, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.7689 - val_loss: -7.7920\n","Epoch 41/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.8219Epoch 00040: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.8244 - val_loss: -7.6825\n","Epoch 42/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.8348Epoch 00041: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.8295 - val_loss: -7.7153\n","Epoch 43/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.8477Epoch 00042: val_loss improved from -7.79205 to -7.80548, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -8.8479 - val_loss: -7.8055\n","Epoch 44/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.8300Epoch 00043: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -8.8290 - val_loss: -7.7481\n","Epoch 45/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.8870Epoch 00044: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.8877 - val_loss: -7.6623\n","Epoch 46/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.8837Epoch 00045: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.8852 - val_loss: -7.7254\n","Epoch 47/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.9110Epoch 00046: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.9123 - val_loss: -7.7313\n","Epoch 48/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.9772Epoch 00047: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.9788 - val_loss: -7.7375\n","Epoch 49/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.9291Epoch 00048: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.9266 - val_loss: -7.6454\n","Epoch 50/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -8.9740Epoch 00049: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -8.9745 - val_loss: -7.7601\n","Epoch 51/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0322Epoch 00050: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0326 - val_loss: -7.7202\n","Epoch 52/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0348Epoch 00051: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0286 - val_loss: -7.7721\n","Epoch 53/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0374Epoch 00052: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0374 - val_loss: -7.7414\n","Epoch 54/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0302Epoch 00053: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0271 - val_loss: -7.6268\n","Epoch 55/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0788Epoch 00054: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0802 - val_loss: -7.7296\n","Epoch 56/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0218Epoch 00055: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0219 - val_loss: -7.7647\n","Epoch 57/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0735Epoch 00056: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0749 - val_loss: -7.7676\n","Epoch 58/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.0626Epoch 00057: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.0630 - val_loss: -7.6826\n","Epoch 59/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1322Epoch 00058: val_loss improved from -7.80548 to -7.81671, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -9.1338 - val_loss: -7.8167\n","Epoch 60/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1181Epoch 00059: val_loss improved from -7.81671 to -7.85936, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -9.1199 - val_loss: -7.8594\n","Epoch 61/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1391Epoch 00060: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1398 - val_loss: -7.7623\n","Epoch 62/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1562Epoch 00061: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1568 - val_loss: -7.7920\n","Epoch 63/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1599Epoch 00062: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1540 - val_loss: -7.8298\n","Epoch 64/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1350Epoch 00063: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1366 - val_loss: -7.7955\n","Epoch 65/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1263Epoch 00064: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1215 - val_loss: -7.7320\n","Epoch 66/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1902Epoch 00065: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1894 - val_loss: -7.7579\n","Epoch 67/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1983Epoch 00066: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1990 - val_loss: -7.7519\n","Epoch 68/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1617Epoch 00067: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1639 - val_loss: -7.8474\n","Epoch 69/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1671Epoch 00068: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1686 - val_loss: -7.7686\n","Epoch 70/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.1738Epoch 00069: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1751 - val_loss: -7.8522\n","Epoch 71/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2005Epoch 00070: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2024 - val_loss: -7.8291\n","Epoch 72/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2074Epoch 00071: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2077 - val_loss: -7.7679\n","Epoch 73/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2382Epoch 00072: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2350 - val_loss: -7.6376\n","Epoch 74/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2184Epoch 00073: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2145 - val_loss: -7.7697\n","Epoch 75/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2796Epoch 00074: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2790 - val_loss: -7.6782\n","Epoch 76/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2032Epoch 00075: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.1988 - val_loss: -7.7595\n","Epoch 77/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2209Epoch 00076: val_loss improved from -7.85936 to -7.87007, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -9.2215 - val_loss: -7.8701\n","Epoch 78/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3008Epoch 00077: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2946 - val_loss: -7.8221\n","Epoch 79/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2375Epoch 00078: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2303 - val_loss: -7.5659\n","Epoch 80/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2863Epoch 00079: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2872 - val_loss: -7.8626\n","Epoch 81/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2742Epoch 00080: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2704 - val_loss: -7.8273\n","Epoch 82/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2661Epoch 00081: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2672 - val_loss: -7.7870\n","Epoch 83/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2692Epoch 00082: val_loss improved from -7.87007 to -7.96543, saving model to temp_weights.h5\n","50000/50000 [==============================] - 47s - loss: -9.2705 - val_loss: -7.9654\n","Epoch 84/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2943Epoch 00083: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -9.2947 - val_loss: -7.8181\n","Epoch 85/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3015Epoch 00084: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3020 - val_loss: -7.7913\n","Epoch 86/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.2854Epoch 00085: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.2868 - val_loss: -7.8324\n","Epoch 87/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3260Epoch 00086: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -9.3197 - val_loss: -7.8805\n","Epoch 88/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3376Epoch 00087: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -9.3388 - val_loss: -7.7780\n","Epoch 89/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3115Epoch 00088: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3082 - val_loss: -7.7899\n","Epoch 90/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3499Epoch 00089: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3477 - val_loss: -7.8490\n","Epoch 91/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3389Epoch 00090: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -9.3394 - val_loss: -7.8792\n","Epoch 92/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3027Epoch 00091: val_loss did not improve\n","50000/50000 [==============================] - 47s - loss: -9.3039 - val_loss: -7.8546\n","Epoch 93/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3823Epoch 00092: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3823 - val_loss: -7.8086\n","Epoch 94/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3724Epoch 00093: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3714 - val_loss: -7.7923\n","Epoch 95/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3875Epoch 00094: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3840 - val_loss: -7.7522\n","Epoch 96/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3201Epoch 00095: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3203 - val_loss: -7.8670\n","Epoch 97/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3919Epoch 00096: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3917 - val_loss: -7.7626\n","Epoch 98/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3914Epoch 00097: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3927 - val_loss: -7.8657\n","Epoch 99/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3618Epoch 00098: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3626 - val_loss: -7.8405\n","Epoch 100/100\n","49600/50000 [============================>.] - ETA: 0s - loss: -9.3750Epoch 00099: val_loss did not improve\n","50000/50000 [==============================] - 46s - loss: -9.3758 - val_loss: -7.8255\n","10000/10000 [==============================] - 3s     \n","loss on test data:  -7.858819908021961\n","10000/10000 [==============================] - 3s     \n","loss on validation data:  -7.965427476272908\n","Linear CCA started!\n","Linear CCA ended!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TiKZzWvya1v","executionInfo":{"status":"ok","timestamp":1620596455079,"user_tz":-330,"elapsed":1509,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"0659cf7e-5361-4374-9dee-d7cb4ecbc482"},"source":["    # Training and testing of SVM with linear kernel on the view 1 with new features\n","    [test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n","    print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n","    print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["training SVM...\n","Accuracy on view 1 (validation data) is: 96.92\n","Accuracy on view 1 (test data) is: 96.64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I96IE6z8E3AF","executionInfo":{"status":"ok","timestamp":1620596467565,"user_tz":-330,"elapsed":1487,"user":{"displayName":"Swathi 172","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGfzn3uxDUdGBEmI35jVmCq-zw0QKH7ZBS2afMjw=s64","userId":"01282203074884786327"}},"outputId":"34c59558-4c6e-4c6b-ac78-55012cbb3edd"},"source":["    # Saving new features in a gzip pickled file specified by save_to\n","    print('saving new features ...')\n","    f1 = gzip.open(save_to, 'wb')\n","    thepickle.dump(new_data, f1)\n","    f1.close()\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["saving new features ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BPw8fajtE6Eh"},"source":[""],"execution_count":null,"outputs":[]}]}